{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from obspy.core import Stream\n",
    "from obspy import read\n",
    "# from geographiclib.geodesic import Geodesic\n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "from obspy.geodetics import kilometers2degrees\n",
    "# import obspy\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BinaryDataDirectory = \"/raid1/Data/LearningEQs/LearningEQs/Earthquakes_Binary\"\n",
    "# BinaryFileName = glob.glob(BinaryDataDirectory+'/*.bin')[0]\n",
    "\n",
    "# DataArrayRead = np.fromfile(BinaryFileName,dtype='float64').reshape(129,7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181111140403\n"
     ]
    }
   ],
   "source": [
    "MseedDataDirectory = \"/raid1/Data/fetch_fdsn_sxd\"\n",
    "# MseedFileName = glob.glob(MseedDataDirectory+'/*.mseed')[0]\n",
    "MseedFileName = MseedDataDirectory+'/20181111140403.mseed'\n",
    "\n",
    "DataStream = read(MseedFileName,format='MSEED')\n",
    "FileName = MseedFileName.split('/')[-1].split('.')[0]\n",
    "print(FileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source and Station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-11 14:04:03.54 15.650 -49.930 12 mw 6.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EventCatalog = dict()\n",
    "with open(\"/raid1/Data/fetch_fdsn_sxd/DATA_REQUEST_CATALOG_ChinaArray.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith(FileName[0:4]+'-'+FileName[4:6]+'-'+FileName[6:8]):\n",
    "            print(line)\n",
    "            SourceLat = float(line.split()[2])\n",
    "            SourceLon = float(line.split()[3])\n",
    "\n",
    "StationCatalog = dict()\n",
    "with open(\"/raid1/Data/fetch_fdsn_sxd/station.meta\", 'r') as f:\n",
    "    for line in f:\n",
    "        StationName = line.split('|')[0] + '.' + line.split('|')[1]\n",
    "        StationCatalog[StationName] = dict()\n",
    "        StationCatalog[StationName]['NetworkCode'] = line.split('|')[0]\n",
    "        StationCatalog[StationName]['StationCode'] = line.split('|')[1]\n",
    "        StationCatalog[StationName]['Channel'] = line.split('|')[3]\n",
    "        StationCatalog[StationName]['Latitude'] = float(line.split('|')[4])\n",
    "        StationCatalog[StationName]['Longitude'] = float(line.split('|')[5])\n",
    "\n",
    "DataStream.trim(starttime=DataStream[0].stats.starttime + 300, endtime=DataStream[0].stats.endtime - 300)\n",
    "for itrace, trace in enumerate(DataStream):\n",
    "    StationName = DataStream[itrace].stats.network + \".\" + DataStream[itrace].stats.station\n",
    "    distm, azimuth, backazimuth = gps2dist_azimuth(SourceLat,SourceLon,StationCatalog[StationName]['Latitude'],StationCatalog[StationName]['Longitude'])\n",
    "    distance_in_degrees = kilometers2degrees(distm/1.0e3)\n",
    "    \n",
    "    DataStream[itrace].stats.distance = distm\n",
    "    DataStream[itrace].stats.distance_in_degrees = distance_in_degrees\n",
    "    DataStream[itrace].stats.azimuth = azimuth\n",
    "    DataStream[itrace].stats.backazimuth = backazimuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate seismogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTZDataStream = Stream()\n",
    "\n",
    "for itrace, trace in enumerate(DataStream.select(component=\"E\")):\n",
    "    EChannelName = DataStream[itrace].stats.network + \".\" + DataStream[itrace].stats.station + \".\" \\\n",
    "                 + DataStream[itrace].stats.location + \".\" \"BHE\"\n",
    "    seisE = DataStream.select(id=EChannelName)\n",
    "    \n",
    "    NChannelName = DataStream[itrace].stats.network + \".\" + DataStream[itrace].stats.station + \".\" \\\n",
    "                 + DataStream[itrace].stats.location + \".\" \"BHN\"\n",
    "    seisN = DataStream.select(id=NChannelName)\n",
    "    \n",
    "    if len(seisE) != 1 or len(seisN) != 1:\n",
    "        continue\n",
    "\n",
    "    ZChannelName = DataStream[itrace].stats.network + \".\" + DataStream[itrace].stats.station + \".\" \\\n",
    "                 + DataStream[itrace].stats.location + \".\" \"BHZ\"\n",
    "    seisZ = DataStream.select(id=ZChannelName)[0]\n",
    "    \n",
    "    \n",
    "    [seisRtmp,seisTtmp] = rotate_ne_rt(seisN[0].data, seisE[0].data, seisN[0].stats.backazimuth)\n",
    "    \n",
    "    seisR=seisN[0].copy()\n",
    "    seisR.stats['channel']='BHR'\n",
    "    seisR.data=seisRtmp\n",
    "    seisT=seisN[0].copy()\n",
    "    seisT.stats['channel']='BHT'\n",
    "    seisT.data=seisTtmp\n",
    "    \n",
    "    RTZDataStream += seisR\n",
    "    RTZDataStream += seisT\n",
    "    RTZDataStream += seisZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTZDataStream.write(\"./Data/%s.PICKLE\" %FileName,format='PICKLE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add traveltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTZDataStream = read(\"./Data/%s.PICKLE\" %FileName,format='PICKLE')\n",
    "Phases = ['S','Sdiff']\n",
    "for itrace, trace in enumerate(DataStream.select(component=\"T\")):\n",
    "    if not hasattr(trace.stats,'traveltimes'):\n",
    "        seis[0].stats.traveltimes=dict()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataStream.plot(type=\"section\") #type=\"normal\n",
    "# print(DataStream[0].stats)\n",
    "# len(DataStream.select(component=\"E\"))\n",
    "len(RTZDataStream.select(component=\"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuted time:  5.927774429321289\n",
      "Excuted time:  6.183201313018799\n"
     ]
    }
   ],
   "source": [
    "Start = time.time()\n",
    "DataStream.write(\"example.mseed\",format='MSEED')\n",
    "End = time.time()\n",
    "print(\"Excuted time: \", End - Start)\n",
    "\n",
    "Start = time.time()\n",
    "DataStream.write(\"example.PICKLE\",format='PICKLE')\n",
    "End = time.time()\n",
    "print(\"Excuted time: \", End - Start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuted time:  2.9123528003692627\n",
      "         network: AH\n",
      "         station: ANQ\n",
      "        location: 00\n",
      "         channel: BHE\n",
      "       starttime: 2018-11-11T13:59:03.000000Z\n",
      "         endtime: 2018-11-11T14:39:03.000000Z\n",
      "   sampling_rate: 100.0\n",
      "           delta: 0.01\n",
      "            npts: 240001\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 462, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 512, 'filesize': 822248960})\n",
      "Excuted time:  4.653659820556641\n",
      "         network: AH\n",
      "         station: ANQ\n",
      "        location: 00\n",
      "         channel: BHE\n",
      "       starttime: 2018-11-11T13:59:03.000000Z\n",
      "         endtime: 2018-11-11T14:39:03.000000Z\n",
      "   sampling_rate: 100.0\n",
      "           delta: 0.01\n",
      "            npts: 240001\n",
      "           calib: 1.0\n",
      "         _format: PICKLE\n",
      "        distance: 14703055.885827696\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 468, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 512, 'filesize': 847546368})\n"
     ]
    }
   ],
   "source": [
    "Start = time.time()\n",
    "DataStream = read(\"example.mseed\",format='MSEED')\n",
    "End = time.time()\n",
    "print(\"Excuted time: \", End - Start)\n",
    "print(DataStream[0].stats)\n",
    "\n",
    "Start = time.time()\n",
    "DataStream = read(\"example.PICKLE\",format='PICKLE')\n",
    "End = time.time()\n",
    "print(\"Excuted time: \", End - Start)\n",
    "print(DataStream[0].stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5da1a19760c645bef876c945e2def5171d007c0fd3f14585be32e516ddabd56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
